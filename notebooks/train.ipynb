{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "\n",
    "CIFAR-10 is one of the best-known image recognition benchmark datasets in the deep learning space. It is an independently relabelled subset of the now-retired 80 Million Tiny Images dataset containing just 10 different classes overall:\n",
    "\n",
    "```csv\n",
    "airplanes,cars,birds,cats,deer,dogs,frogs,horses,ships,trucks\n",
    "```\n",
    "\n",
    "The model from the paper accompanying the release of this dataset was 20% inacurrate at the time of the dataset's release in 2009-2010. A ResNet achieved 4% inaccuracy on this classification task back in 2016. As of 2020, benchmark inaccuracy on this task has dropped down to around 1%, according to [paperswithcode](https://paperswithcode.com/sota/image-classification-on-cifar-10), rendering this simple benchmark dataset a (mostly) solved problem. How far we've come in ten years!\n",
    "\n",
    "In this notebook we will train a simple convolutional neural net (CNN), written in PyTorch, on this dataset, demonstrating some of features of the Spell platform in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial model\n",
    "\n",
    "`CIFAR10` is available as a prepackaged dataset via `torchvision.data`. Note that, as a convention, we recommend downloading/mounting datasets to the `/mnt/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomPerspective(),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: /mnt/cifar10/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomPerspective(p=0.5)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex, y_ex = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ex.shape, y_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5137, 0.5294, 0.5294,  ..., 0.5412, 0.5373, 0.5294],\n",
       "         [0.5451, 0.5529, 0.5569,  ..., 0.5686, 0.5569, 0.5647],\n",
       "         [0.5804, 0.5882, 0.5922,  ..., 0.6039, 0.5922, 0.6039],\n",
       "         ...,\n",
       "         [0.0157, 0.0353, 0.0196,  ..., 0.8824, 0.8902, 0.8902],\n",
       "         [0.0118, 0.0196, 0.0157,  ..., 0.8745, 0.8784, 0.8784],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8588, 0.8392, 0.8431]],\n",
       "\n",
       "        [[0.7059, 0.7137, 0.7216,  ..., 0.7294, 0.7176, 0.7255],\n",
       "         [0.7098, 0.7176, 0.7176,  ..., 0.7255, 0.7216, 0.7294],\n",
       "         [0.7333, 0.7373, 0.7373,  ..., 0.7451, 0.7451, 0.7529],\n",
       "         ...,\n",
       "         [0.0039, 0.0196, 0.0196,  ..., 0.8745, 0.8863, 0.8902],\n",
       "         [0.0039, 0.0078, 0.0157,  ..., 0.8706, 0.8784, 0.8824],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8667, 0.8392, 0.8431]],\n",
       "\n",
       "        [[0.8510, 0.8627, 0.8627,  ..., 0.8706, 0.8627, 0.8588],\n",
       "         [0.8510, 0.8588, 0.8510,  ..., 0.8588, 0.8588, 0.8549],\n",
       "         [0.8627, 0.8667, 0.8627,  ..., 0.8745, 0.8784, 0.8667],\n",
       "         ...,\n",
       "         [0.0078, 0.0235, 0.0196,  ..., 0.8902, 0.8980, 0.8863],\n",
       "         [0.0039, 0.0078, 0.0157,  ..., 0.8824, 0.8863, 0.8784],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8627, 0.8549, 0.8510]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 9, 9, 8, 1, 8, 2, 2, 0, 2, 0, 0, 8, 7, 8, 5, 9, 7, 2, 0, 6, 1, 9, 2,\n",
       "        5, 7, 7, 8, 5, 9, 6, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the model. This model is a PyTorch implementation of `cifar10_cnn.py` from [Keras's example repository](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py). This is a very simple convolutional net with a feedforward head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(*[\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25)\n",
    "        ])\n",
    "        self.cnn_block_2 = nn.Sequential(*[\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25)\n",
    "        ])\n",
    "        self.flatten = lambda inp: torch.flatten(inp, 1)\n",
    "        self.head = nn.Sequential(*[\n",
    "            nn.Linear(800, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.cnn_block_1(X)\n",
    "        X = self.cnn_block_2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.head(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0564, -0.0351, -0.0408,  0.0134, -0.0342,  0.0464, -0.0170, -0.0187,\n",
       "          0.0066,  0.1017],\n",
       "        [ 0.0363, -0.0267, -0.0080,  0.0199, -0.0397,  0.0223,  0.0141, -0.0222,\n",
       "          0.0240,  0.0678],\n",
       "        [ 0.0201, -0.0339, -0.0081,  0.0263, -0.0137,  0.0421,  0.0132, -0.0238,\n",
       "          0.0063,  0.0338],\n",
       "        [ 0.0316, -0.0498, -0.0134, -0.0228, -0.0386,  0.0235,  0.0184, -0.0051,\n",
       "          0.0069,  0.0663],\n",
       "        [ 0.0459, -0.0410, -0.0340,  0.0152, -0.0261,  0.0106, -0.0131, -0.0257,\n",
       "         -0.0175,  0.0725],\n",
       "        [ 0.0168, -0.0545, -0.0368,  0.0115, -0.0336,  0.0123,  0.0006, -0.0544,\n",
       "         -0.0121,  0.0392],\n",
       "        [ 0.0511, -0.0244, -0.0268,  0.0225, -0.0433,  0.0171, -0.0108, -0.0183,\n",
       "         -0.0120,  0.0647],\n",
       "        [ 0.0187, -0.0182, -0.0229,  0.0184,  0.0037,  0.0273, -0.0214, -0.0423,\n",
       "          0.0150,  0.0753],\n",
       "        [ 0.0419, -0.0385, -0.0244,  0.0510, -0.0440,  0.0714,  0.0249, -0.0244,\n",
       "          0.0277,  0.0620],\n",
       "        [-0.0140, -0.0193, -0.0492,  0.0153, -0.0422,  0.0526, -0.0017, -0.0382,\n",
       "         -0.0250,  0.0929],\n",
       "        [ 0.0406, -0.0034, -0.0401,  0.0252, -0.0334,  0.0398, -0.0131, -0.0250,\n",
       "         -0.0379,  0.0437],\n",
       "        [ 0.0166, -0.0425, -0.0434,  0.0379,  0.0063,  0.0081,  0.0134, -0.0398,\n",
       "          0.0149,  0.0775],\n",
       "        [ 0.0150, -0.0353, -0.0156,  0.0268, -0.0353,  0.0362, -0.0126, -0.0297,\n",
       "         -0.0227,  0.0646],\n",
       "        [ 0.0038, -0.0155, -0.0627,  0.0533, -0.0162,  0.0050, -0.0317, -0.0072,\n",
       "         -0.0046,  0.0515],\n",
       "        [ 0.0203, -0.0267, -0.0354,  0.0278, -0.0445,  0.0172,  0.0207, -0.0174,\n",
       "          0.0210,  0.0594],\n",
       "        [ 0.0142, -0.0381, -0.0520,  0.0207, -0.0300,  0.0281, -0.0013, -0.0481,\n",
       "         -0.0151,  0.0598],\n",
       "        [ 0.0413, -0.0377, -0.0358,  0.0449, -0.0227,  0.0289, -0.0365, -0.0222,\n",
       "          0.0082,  0.0749],\n",
       "        [ 0.0042, -0.0247, -0.0384, -0.0163, -0.0216,  0.0070,  0.0182, -0.0249,\n",
       "         -0.0245,  0.0717],\n",
       "        [ 0.0422, -0.0565, -0.0077,  0.0275, -0.0505,  0.0347,  0.0374, -0.0316,\n",
       "          0.0165,  0.0670],\n",
       "        [ 0.0355, -0.0277, -0.0374,  0.0226, -0.0294,  0.0488, -0.0137, -0.0472,\n",
       "          0.0006,  0.0580],\n",
       "        [ 0.0491, -0.0395, -0.0358,  0.0186, -0.0023,  0.0380,  0.0034, -0.0272,\n",
       "         -0.0221,  0.0480],\n",
       "        [ 0.0068, -0.0416, -0.0312,  0.0232, -0.0229,  0.0265,  0.0140, -0.0242,\n",
       "         -0.0030,  0.0737],\n",
       "        [ 0.0173, -0.0371, -0.0017,  0.0017, -0.0371,  0.0062, -0.0073, -0.0353,\n",
       "          0.0007,  0.0959],\n",
       "        [ 0.0166, -0.0550, -0.0282,  0.0172, -0.0392,  0.0197, -0.0079, -0.0470,\n",
       "         -0.0060,  0.0354],\n",
       "        [ 0.0063, -0.0269, -0.0366,  0.0070, -0.0314,  0.0433, -0.0073, -0.0453,\n",
       "         -0.0056,  0.0533],\n",
       "        [ 0.0351, -0.0329, -0.0459,  0.0369, -0.0399,  0.0186, -0.0031, -0.0309,\n",
       "         -0.0033,  0.0789],\n",
       "        [-0.0019, -0.0334, -0.0317,  0.0144, -0.0156,  0.0171,  0.0134, -0.0173,\n",
       "         -0.0079,  0.0381],\n",
       "        [ 0.0454, -0.0478, -0.0241,  0.0135, -0.0356,  0.0279, -0.0169, -0.0227,\n",
       "         -0.0025,  0.0666],\n",
       "        [ 0.0316, -0.0333, -0.0459,  0.0137, -0.0027,  0.0050,  0.0060, -0.0152,\n",
       "         -0.0083,  0.0525],\n",
       "        [ 0.0146, -0.0124, -0.0334,  0.0183, -0.0227,  0.0547, -0.0021, -0.0364,\n",
       "          0.0007,  0.0722],\n",
       "        [ 0.0278, -0.0203, -0.0356,  0.0435, -0.0326,  0.0510,  0.0169,  0.0105,\n",
       "          0.0059,  0.0475],\n",
       "        [ 0.0590, -0.0437, -0.0365,  0.0103, -0.0286,  0.0212, -0.0220, -0.0374,\n",
       "          0.0029,  0.0377]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CIFAR10Model()\n",
    "clf.cuda()\n",
    "clf.forward(X_ex.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(clf.forward(X_ex.cuda()), y_ex.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train():\n",
    "    NUM_EPOCHS = 10\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        losses = []\n",
    "\n",
    "        for i, (X_batch, y_cls) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y = y_cls.cuda()\n",
    "            X_batch = X_batch.cuda()\n",
    "\n",
    "            y_pred = clf(X_batch)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_loss = loss.item()\n",
    "            if i % 200 == 0:\n",
    "                print(\n",
    "                    f'Finished epoch {epoch}/{NUM_EPOCHS}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "                )\n",
    "\n",
    "            losses.append(curr_loss)\n",
    "\n",
    "        print(\n",
    "            f'Finished epoch {epoch}. '\n",
    "            f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1/10, batch 0. Loss: 2.296.\n",
      "Finished epoch 1/10, batch 200. Loss: 1.928.\n",
      "Finished epoch 1/10, batch 400. Loss: 1.823.\n",
      "Finished epoch 1/10, batch 600. Loss: 1.735.\n",
      "Finished epoch 1/10, batch 800. Loss: 1.578.\n",
      "Finished epoch 1/10, batch 1000. Loss: 1.532.\n",
      "Finished epoch 1/10, batch 1200. Loss: 1.561.\n",
      "Finished epoch 1/10, batch 1400. Loss: 1.461.\n",
      "Finished epoch 1. avg loss: 1.7841214290888585; median loss: 1.163797378540039\n",
      "Finished epoch 2/10, batch 0. Loss: 1.663.\n",
      "Finished epoch 2/10, batch 200. Loss: 1.401.\n",
      "Finished epoch 2/10, batch 400. Loss: 1.728.\n",
      "Finished epoch 2/10, batch 600. Loss: 1.167.\n",
      "Finished epoch 2/10, batch 800. Loss: 1.632.\n",
      "Finished epoch 2/10, batch 1000. Loss: 1.687.\n",
      "Finished epoch 2/10, batch 1200. Loss: 1.801.\n",
      "Finished epoch 2/10, batch 1400. Loss: 1.213.\n",
      "Finished epoch 2. avg loss: 1.4924049427397954; median loss: 0.9426190853118896\n",
      "Finished epoch 3/10, batch 0. Loss: 1.706.\n",
      "Finished epoch 3/10, batch 200. Loss: 1.484.\n",
      "Finished epoch 3/10, batch 400. Loss: 1.394.\n",
      "Finished epoch 3/10, batch 600. Loss: 1.347.\n",
      "Finished epoch 3/10, batch 800. Loss: 1.094.\n",
      "Finished epoch 3/10, batch 1000. Loss: 1.357.\n",
      "Finished epoch 3/10, batch 1200. Loss: 1.483.\n",
      "Finished epoch 3/10, batch 1400. Loss: 1.029.\n",
      "Finished epoch 3. avg loss: 1.3683954923868331; median loss: 0.8242694735527039\n",
      "Finished epoch 4/10, batch 0. Loss: 1.327.\n",
      "Finished epoch 4/10, batch 200. Loss: 1.326.\n",
      "Finished epoch 4/10, batch 400. Loss: 1.516.\n",
      "Finished epoch 4/10, batch 600. Loss: 1.455.\n",
      "Finished epoch 4/10, batch 800. Loss: 1.455.\n",
      "Finished epoch 4/10, batch 1000. Loss: 1.264.\n",
      "Finished epoch 4/10, batch 1200. Loss: 1.183.\n",
      "Finished epoch 4/10, batch 1400. Loss: 1.403.\n",
      "Finished epoch 4. avg loss: 1.296982744338035; median loss: 0.715129554271698\n",
      "Finished epoch 5/10, batch 0. Loss: 1.513.\n",
      "Finished epoch 5/10, batch 200. Loss: 1.484.\n",
      "Finished epoch 5/10, batch 400. Loss: 0.869.\n",
      "Finished epoch 5/10, batch 600. Loss: 0.864.\n",
      "Finished epoch 5/10, batch 800. Loss: 1.392.\n",
      "Finished epoch 5/10, batch 1000. Loss: 1.699.\n",
      "Finished epoch 5/10, batch 1200. Loss: 1.527.\n",
      "Finished epoch 5/10, batch 1400. Loss: 1.036.\n",
      "Finished epoch 5. avg loss: 1.2470163554239182; median loss: 0.7198798060417175\n",
      "Finished epoch 6/10, batch 0. Loss: 1.391.\n",
      "Finished epoch 6/10, batch 200. Loss: 1.185.\n",
      "Finished epoch 6/10, batch 400. Loss: 1.183.\n",
      "Finished epoch 6/10, batch 600. Loss: 1.528.\n",
      "Finished epoch 6/10, batch 800. Loss: 1.402.\n",
      "Finished epoch 6/10, batch 1000. Loss: 1.349.\n",
      "Finished epoch 6/10, batch 1200. Loss: 1.476.\n",
      "Finished epoch 6/10, batch 1400. Loss: 1.640.\n",
      "Finished epoch 6. avg loss: 1.2092364381615046; median loss: 0.6886485815048218\n",
      "Finished epoch 7/10, batch 0. Loss: 1.063.\n",
      "Finished epoch 7/10, batch 200. Loss: 0.900.\n",
      "Finished epoch 7/10, batch 400. Loss: 1.152.\n",
      "Finished epoch 7/10, batch 600. Loss: 1.671.\n",
      "Finished epoch 7/10, batch 800. Loss: 1.224.\n",
      "Finished epoch 7/10, batch 1000. Loss: 1.109.\n",
      "Finished epoch 7/10, batch 1200. Loss: 1.293.\n",
      "Finished epoch 7/10, batch 1400. Loss: 1.259.\n",
      "Finished epoch 7. avg loss: 1.1742301879978607; median loss: 0.6198084950447083\n",
      "Finished epoch 8/10, batch 0. Loss: 1.118.\n",
      "Finished epoch 8/10, batch 200. Loss: 1.255.\n",
      "Finished epoch 8/10, batch 400. Loss: 1.238.\n",
      "Finished epoch 8/10, batch 600. Loss: 1.750.\n",
      "Finished epoch 8/10, batch 800. Loss: 1.138.\n",
      "Finished epoch 8/10, batch 1000. Loss: 1.527.\n",
      "Finished epoch 8/10, batch 1200. Loss: 1.341.\n",
      "Finished epoch 8/10, batch 1400. Loss: 0.875.\n",
      "Finished epoch 8. avg loss: 1.1514241900569113; median loss: 0.6431064605712891\n",
      "Finished epoch 9/10, batch 0. Loss: 0.719.\n",
      "Finished epoch 9/10, batch 200. Loss: 1.446.\n",
      "Finished epoch 9/10, batch 400. Loss: 0.914.\n",
      "Finished epoch 9/10, batch 600. Loss: 0.927.\n",
      "Finished epoch 9/10, batch 800. Loss: 1.012.\n",
      "Finished epoch 9/10, batch 1000. Loss: 1.123.\n",
      "Finished epoch 9/10, batch 1200. Loss: 1.261.\n",
      "Finished epoch 9/10, batch 1400. Loss: 1.051.\n",
      "Finished epoch 9. avg loss: 1.1225617870411961; median loss: 0.5962265729904175\n",
      "Finished epoch 10/10, batch 0. Loss: 0.938.\n",
      "Finished epoch 10/10, batch 200. Loss: 1.026.\n",
      "Finished epoch 10/10, batch 400. Loss: 0.892.\n",
      "Finished epoch 10/10, batch 600. Loss: 1.223.\n",
      "Finished epoch 10/10, batch 800. Loss: 1.055.\n",
      "Finished epoch 10/10, batch 1000. Loss: 0.908.\n",
      "Finished epoch 10/10, batch 1200. Loss: 1.044.\n",
      "Finished epoch 10/10, batch 1400. Loss: 0.669.\n",
      "Finished epoch 10. avg loss: 1.1084050065191298; median loss: 0.5273211598396301\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That completes our initial model definition. I added checkpointing and metrics tracking (via `send_metric`) to the following training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../models/train_basic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/train_basic.py\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from spell.metrics import send_metric\n",
    "\n",
    "import os\n",
    "if not os.path.exists(\"/spell/checkpoints/\"):\n",
    "    os.mkdir(\"/spell/checkpoints/\")\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomPerspective(),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(*[\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25)\n",
    "        ])\n",
    "        self.cnn_block_2 = nn.Sequential(*[\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25)\n",
    "        ])\n",
    "        self.flatten = lambda inp: torch.flatten(inp, 1)\n",
    "        self.head = nn.Sequential(*[\n",
    "            nn.Linear(800, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.cnn_block_1(X)\n",
    "        X = self.cnn_block_2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.head(X)\n",
    "        return X\n",
    "\n",
    "clf = CIFAR10Model()\n",
    "clf.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clf.parameters())\n",
    "\n",
    "def train():\n",
    "    NUM_EPOCHS = 10\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        losses = []\n",
    "\n",
    "        for i, (X_batch, y_cls) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y = y_cls.cuda()\n",
    "            X_batch = X_batch.cuda()\n",
    "\n",
    "            y_pred = clf(X_batch)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_loss = loss.item()\n",
    "            if i % 200 == 0:\n",
    "                print(\n",
    "                    f'Finished epoch {epoch}/{NUM_EPOCHS}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "                )\n",
    "                send_metric(\"loss\", curr_loss)\n",
    "\n",
    "            losses.append(curr_loss)\n",
    "\n",
    "        print(\n",
    "            f'Finished epoch {epoch}. '\n",
    "            f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "        )\n",
    "        \n",
    "        torch.save(clf.state_dict(), f\"/spell/checkpoints/epoch_{epoch}.pth\")\n",
    "    torch.save(clf.state_dict(), f\"/spell/checkpoints/model_final.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are on a dirty commit because we created this notebook file and this model training script in a Spell workspace, and it does not yet exist in the backing `git` repository (for more on how Spell runs and workspaces interact with git refer to [\"How runs interact with git\"](https://spell.ml/docs/run_overview#how-runs-interact-with-git) in our docs). The good news is that this is easy to do using our built-in JupyterLab git extension ([`jupyterlab/jupyterlab-git`](https://github.com/jupyterlab/jupyterlab-git)) on the sidebar:\n",
    "\n",
    "![](https://i.imgur.com/zRUN7vh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33mWARNING: \u001b[0mLog out failed for previous session: Unknown Server Error\n",
      "\u001b[0m\u001b[0mHello, Aleksey Bilogur!\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# This is temporarily necessary.\n",
    "# !spell login --identity aleksey@spell.ml --password jF4D@4#meRZF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mðŸ’« Casting spell #88â€¦\n",
      "\u001b[0mâœ¨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Machine_Requestedâ€¦ done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Buildingâ€¦ done tagged registry.spell.ml/remote_content_88:a344cabc61â€¦\u001b[0mm\n",
      "\u001b[0mâœ¨ \u001b[0mRun is running\n",
      "\u001b[0mDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /mnt/cifar10/cifar-10-python.tar.gz\n",
      "170500096it [00:08, 19503771.75it/s]                               \n",
      "\u001b[0mExtracting /mnt/cifar10/cifar-10-python.tar.gz to /mnt/cifar10/\n",
      "\u001b[0m^C\n",
      "\n",
      "\u001b[0mâœ¨ Your run is still running remotely.\n",
      "\u001b[0mâœ¨ Use 'spell kill 88' to terminate your run\n",
      "\u001b[0mâœ¨ Use 'spell logs 88' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type t4 \\\n",
    "    --github-url https://github.com/spellml/cnn-cifar10.git \\\n",
    "    python models/train_basic.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improved model training script\n",
    "\n",
    "The following updated training script includes several additional bells and whistles typical of a Spell run model training script:\n",
    "\n",
    "* Model checkpointing has been added. If a checkpoint file is present, the training job will resume from the latest checkpoint automatically.\n",
    "* You can specify that the run use the dataset on disk, and error if it doesn't exist, using a command line flag.\n",
    "* The number of epochs, convolutional block dropout, output head dropout, convolutional filter count, and dense layer filter count are all configurable using command line arguments.\n",
    "* Logs to Spell metrics.\n",
    "* Logs to Tensorboard.\n",
    "* Added a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../models/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/train.py\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "from spell.metrics import send_metric\n",
    "\n",
    "import os\n",
    "if not os.path.exists(\"/spell/checkpoints/\"):\n",
    "    os.mkdir(\"/spell/checkpoints/\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', type=int, dest='epochs', default=50)\n",
    "parser.add_argument('--batch_size', type=int, dest='batch_size', default=32)\n",
    "\n",
    "parser.add_argument('--conv1_filters', type=int, dest='conv1_filters', default=32)\n",
    "parser.add_argument('--conv2_filters', type=int, dest='conv2_filters', default=32)\n",
    "parser.add_argument('--dense_layer', type=int, dest='dense_layer', default=512)\n",
    "\n",
    "parser.add_argument('--conv1_dropout', type=float, dest='conv1_dropout', default=0.25)\n",
    "parser.add_argument('--conv2_dropout', type=float, dest='conv2_dropout', default=0.25)\n",
    "parser.add_argument('--dense_dropout', type=float, dest='dense_dropout', default=0.5)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomPerspective(),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(*[\n",
    "            nn.Conv2d(3, args.conv1_filters, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(args.conv1_filters, args.conv1_filters, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(args.conv1_dropout)\n",
    "        ])\n",
    "        self.cnn_block_2 = nn.Sequential(*[\n",
    "            nn.Conv2d(args.conv2_filters, args.conv2_filters, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(args.conv2_filters, args.conv2_filters, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(args.conv2_dropout)\n",
    "        ])\n",
    "        self.flatten = lambda inp: torch.flatten(inp, 1)\n",
    "        self.head = nn.Sequential(*[\n",
    "            nn.Linear(800, args.dense_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(args.dense_dropout),\n",
    "            nn.Linear(args.dense_layer, 10)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.cnn_block_1(X)\n",
    "        X = self.cnn_block_2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.head(X)\n",
    "        return X\n",
    "\n",
    "clf = CIFAR10Model()\n",
    "clf.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clf.parameters())\n",
    "\n",
    "def train():\n",
    "    NUM_EPOCHS = args.epochs\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        losses = []\n",
    "\n",
    "        for i, (X_batch, y_cls) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y = y_cls.cuda()\n",
    "            X_batch = X_batch.cuda()\n",
    "\n",
    "            y_pred = clf(X_batch)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_loss = loss.item()\n",
    "            if i % 200 == 0:\n",
    "                print(\n",
    "                    f'Finished epoch {epoch}/{NUM_EPOCHS}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "                )\n",
    "                send_metric(\"loss\", curr_loss)\n",
    "\n",
    "            losses.append(curr_loss)\n",
    " \n",
    "        print(\n",
    "            f'Finished epoch {epoch}. '\n",
    "            f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "        )\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(clf.state_dict(), f\"/spell/checkpoints/epoch_{epoch}.pth\")\n",
    "    torch.save(clf.state_dict(), f\"/spell/checkpoints/model_final.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything up-to-date\n",
      "\u001b[0mðŸ’« Casting spell #78â€¦\n",
      "\u001b[0mâœ¨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Buildingâ€¦ doneode\u001b[0mm\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Machine_Requestedâ€¦ done tagged registry.spell.ml/external-aws/85c7c7â€¦\u001b[0mm\n",
      "\u001b[0mâœ¨ \u001b[0mRun is running\n",
      "\u001b[0m^C\n",
      "\n",
      "\u001b[0mâœ¨ Your run is still running remotely.\n",
      "\u001b[0mâœ¨ Use 'spell kill 78' to terminate your run\n",
      "\u001b[0mâœ¨ Use 'spell logs 78' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type t4 python ../models/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
