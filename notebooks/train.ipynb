{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "\n",
    "CIFAR-10 is one of the best-known image recognition benchmark datasets in the deep learning space. It is an independently relabelled subset of the now-retired 80 Million Tiny Images dataset containing just 10 different classes overall:\n",
    "\n",
    "```csv\n",
    "airplanes,cars,birds,cats,deer,dogs,frogs,horses,ships,trucks\n",
    "```\n",
    "\n",
    "The model from the paper accompanying the release of this dataset was 20% inacurrate at the time of the dataset's release in 2009-2010. A ResNet achieved 4% inaccuracy on this classification task back in 2016. As of 2020, benchmark inaccuracy on this task has dropped down to around 1%, according to [paperswithcode](https://paperswithcode.com/sota/image-classification-on-cifar-10), rendering this simple benchmark dataset a (mostly) solved problem. How far we've come in ten years!\n",
    "\n",
    "In this notebook we will train a simple convolutional neural net (CNN), written in PyTorch, on this dataset, demonstrating some of features of the Spell platform in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial model\n",
    "\n",
    "`CIFAR10` is available as a prepackaged dataset via `torchvision.data`. Note that, as a convention, we recommend downloading/mounting datasets to the `/mnt/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomPerspective(),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: /mnt/cifar10/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomPerspective(p=0.5)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex, y_ex = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ex.shape, y_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5137, 0.5294, 0.5294,  ..., 0.5412, 0.5373, 0.5294],\n",
       "         [0.5451, 0.5529, 0.5569,  ..., 0.5686, 0.5569, 0.5647],\n",
       "         [0.5804, 0.5882, 0.5922,  ..., 0.6039, 0.5922, 0.6039],\n",
       "         ...,\n",
       "         [0.0157, 0.0353, 0.0196,  ..., 0.8824, 0.8902, 0.8902],\n",
       "         [0.0118, 0.0196, 0.0157,  ..., 0.8745, 0.8784, 0.8784],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8588, 0.8392, 0.8431]],\n",
       "\n",
       "        [[0.7059, 0.7137, 0.7216,  ..., 0.7294, 0.7176, 0.7255],\n",
       "         [0.7098, 0.7176, 0.7176,  ..., 0.7255, 0.7216, 0.7294],\n",
       "         [0.7333, 0.7373, 0.7373,  ..., 0.7451, 0.7451, 0.7529],\n",
       "         ...,\n",
       "         [0.0039, 0.0196, 0.0196,  ..., 0.8745, 0.8863, 0.8902],\n",
       "         [0.0039, 0.0078, 0.0157,  ..., 0.8706, 0.8784, 0.8824],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8667, 0.8392, 0.8431]],\n",
       "\n",
       "        [[0.8510, 0.8627, 0.8627,  ..., 0.8706, 0.8627, 0.8588],\n",
       "         [0.8510, 0.8588, 0.8510,  ..., 0.8588, 0.8588, 0.8549],\n",
       "         [0.8627, 0.8667, 0.8627,  ..., 0.8745, 0.8784, 0.8667],\n",
       "         ...,\n",
       "         [0.0078, 0.0235, 0.0196,  ..., 0.8902, 0.8980, 0.8863],\n",
       "         [0.0039, 0.0078, 0.0157,  ..., 0.8824, 0.8863, 0.8784],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8627, 0.8549, 0.8510]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 9, 9, 8, 1, 8, 2, 2, 0, 2, 0, 0, 8, 7, 8, 5, 9, 7, 2, 0, 6, 1, 9, 2,\n",
       "        5, 7, 7, 8, 5, 9, 6, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the model. This model is a PyTorch implementation of `cifar10_cnn.py` from [Keras's example repository](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py). This is a very simple convolutional net with a feedforward head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(*[\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25)\n",
    "        ])\n",
    "        self.cnn_block_2 = nn.Sequential(*[\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25)\n",
    "        ])\n",
    "        self.flatten = lambda inp: torch.flatten(inp, 1)\n",
    "        self.head = nn.Sequential(*[\n",
    "            nn.Linear(800, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.cnn_block_1(X)\n",
    "        X = self.cnn_block_2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.head(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0564, -0.0351, -0.0408,  0.0134, -0.0342,  0.0464, -0.0170, -0.0187,\n",
       "          0.0066,  0.1017],\n",
       "        [ 0.0363, -0.0267, -0.0080,  0.0199, -0.0397,  0.0223,  0.0141, -0.0222,\n",
       "          0.0240,  0.0678],\n",
       "        [ 0.0201, -0.0339, -0.0081,  0.0263, -0.0137,  0.0421,  0.0132, -0.0238,\n",
       "          0.0063,  0.0338],\n",
       "        [ 0.0316, -0.0498, -0.0134, -0.0228, -0.0386,  0.0235,  0.0184, -0.0051,\n",
       "          0.0069,  0.0663],\n",
       "        [ 0.0459, -0.0410, -0.0340,  0.0152, -0.0261,  0.0106, -0.0131, -0.0257,\n",
       "         -0.0175,  0.0725],\n",
       "        [ 0.0168, -0.0545, -0.0368,  0.0115, -0.0336,  0.0123,  0.0006, -0.0544,\n",
       "         -0.0121,  0.0392],\n",
       "        [ 0.0511, -0.0244, -0.0268,  0.0225, -0.0433,  0.0171, -0.0108, -0.0183,\n",
       "         -0.0120,  0.0647],\n",
       "        [ 0.0187, -0.0182, -0.0229,  0.0184,  0.0037,  0.0273, -0.0214, -0.0423,\n",
       "          0.0150,  0.0753],\n",
       "        [ 0.0419, -0.0385, -0.0244,  0.0510, -0.0440,  0.0714,  0.0249, -0.0244,\n",
       "          0.0277,  0.0620],\n",
       "        [-0.0140, -0.0193, -0.0492,  0.0153, -0.0422,  0.0526, -0.0017, -0.0382,\n",
       "         -0.0250,  0.0929],\n",
       "        [ 0.0406, -0.0034, -0.0401,  0.0252, -0.0334,  0.0398, -0.0131, -0.0250,\n",
       "         -0.0379,  0.0437],\n",
       "        [ 0.0166, -0.0425, -0.0434,  0.0379,  0.0063,  0.0081,  0.0134, -0.0398,\n",
       "          0.0149,  0.0775],\n",
       "        [ 0.0150, -0.0353, -0.0156,  0.0268, -0.0353,  0.0362, -0.0126, -0.0297,\n",
       "         -0.0227,  0.0646],\n",
       "        [ 0.0038, -0.0155, -0.0627,  0.0533, -0.0162,  0.0050, -0.0317, -0.0072,\n",
       "         -0.0046,  0.0515],\n",
       "        [ 0.0203, -0.0267, -0.0354,  0.0278, -0.0445,  0.0172,  0.0207, -0.0174,\n",
       "          0.0210,  0.0594],\n",
       "        [ 0.0142, -0.0381, -0.0520,  0.0207, -0.0300,  0.0281, -0.0013, -0.0481,\n",
       "         -0.0151,  0.0598],\n",
       "        [ 0.0413, -0.0377, -0.0358,  0.0449, -0.0227,  0.0289, -0.0365, -0.0222,\n",
       "          0.0082,  0.0749],\n",
       "        [ 0.0042, -0.0247, -0.0384, -0.0163, -0.0216,  0.0070,  0.0182, -0.0249,\n",
       "         -0.0245,  0.0717],\n",
       "        [ 0.0422, -0.0565, -0.0077,  0.0275, -0.0505,  0.0347,  0.0374, -0.0316,\n",
       "          0.0165,  0.0670],\n",
       "        [ 0.0355, -0.0277, -0.0374,  0.0226, -0.0294,  0.0488, -0.0137, -0.0472,\n",
       "          0.0006,  0.0580],\n",
       "        [ 0.0491, -0.0395, -0.0358,  0.0186, -0.0023,  0.0380,  0.0034, -0.0272,\n",
       "         -0.0221,  0.0480],\n",
       "        [ 0.0068, -0.0416, -0.0312,  0.0232, -0.0229,  0.0265,  0.0140, -0.0242,\n",
       "         -0.0030,  0.0737],\n",
       "        [ 0.0173, -0.0371, -0.0017,  0.0017, -0.0371,  0.0062, -0.0073, -0.0353,\n",
       "          0.0007,  0.0959],\n",
       "        [ 0.0166, -0.0550, -0.0282,  0.0172, -0.0392,  0.0197, -0.0079, -0.0470,\n",
       "         -0.0060,  0.0354],\n",
       "        [ 0.0063, -0.0269, -0.0366,  0.0070, -0.0314,  0.0433, -0.0073, -0.0453,\n",
       "         -0.0056,  0.0533],\n",
       "        [ 0.0351, -0.0329, -0.0459,  0.0369, -0.0399,  0.0186, -0.0031, -0.0309,\n",
       "         -0.0033,  0.0789],\n",
       "        [-0.0019, -0.0334, -0.0317,  0.0144, -0.0156,  0.0171,  0.0134, -0.0173,\n",
       "         -0.0079,  0.0381],\n",
       "        [ 0.0454, -0.0478, -0.0241,  0.0135, -0.0356,  0.0279, -0.0169, -0.0227,\n",
       "         -0.0025,  0.0666],\n",
       "        [ 0.0316, -0.0333, -0.0459,  0.0137, -0.0027,  0.0050,  0.0060, -0.0152,\n",
       "         -0.0083,  0.0525],\n",
       "        [ 0.0146, -0.0124, -0.0334,  0.0183, -0.0227,  0.0547, -0.0021, -0.0364,\n",
       "          0.0007,  0.0722],\n",
       "        [ 0.0278, -0.0203, -0.0356,  0.0435, -0.0326,  0.0510,  0.0169,  0.0105,\n",
       "          0.0059,  0.0475],\n",
       "        [ 0.0590, -0.0437, -0.0365,  0.0103, -0.0286,  0.0212, -0.0220, -0.0374,\n",
       "          0.0029,  0.0377]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CIFAR10Model()\n",
    "clf.cuda()\n",
    "clf.forward(X_ex.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(clf.forward(X_ex.cuda()), y_ex.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train():\n",
    "    NUM_EPOCHS = 10\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        losses = []\n",
    "\n",
    "        for i, (X_batch, y_cls) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y = y_cls.cuda()\n",
    "            X_batch = X_batch.cuda()\n",
    "\n",
    "            y_pred = clf(X_batch)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_loss = loss.item()\n",
    "            if i % 200 == 0:\n",
    "                print(\n",
    "                    f'Finished epoch {epoch}/{NUM_EPOCHS}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "                )\n",
    "\n",
    "            losses.append(curr_loss)\n",
    "\n",
    "        print(\n",
    "            f'Finished epoch {epoch}. '\n",
    "            f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1/10, batch 0. Loss: 2.296.\n",
      "Finished epoch 1/10, batch 200. Loss: 1.928.\n",
      "Finished epoch 1/10, batch 400. Loss: 1.823.\n",
      "Finished epoch 1/10, batch 600. Loss: 1.735.\n",
      "Finished epoch 1/10, batch 800. Loss: 1.578.\n",
      "Finished epoch 1/10, batch 1000. Loss: 1.532.\n",
      "Finished epoch 1/10, batch 1200. Loss: 1.561.\n",
      "Finished epoch 1/10, batch 1400. Loss: 1.461.\n",
      "Finished epoch 1. avg loss: 1.7841214290888585; median loss: 1.163797378540039\n",
      "Finished epoch 2/10, batch 0. Loss: 1.663.\n",
      "Finished epoch 2/10, batch 200. Loss: 1.401.\n",
      "Finished epoch 2/10, batch 400. Loss: 1.728.\n",
      "Finished epoch 2/10, batch 600. Loss: 1.167.\n",
      "Finished epoch 2/10, batch 800. Loss: 1.632.\n",
      "Finished epoch 2/10, batch 1000. Loss: 1.687.\n",
      "Finished epoch 2/10, batch 1200. Loss: 1.801.\n",
      "Finished epoch 2/10, batch 1400. Loss: 1.213.\n",
      "Finished epoch 2. avg loss: 1.4924049427397954; median loss: 0.9426190853118896\n",
      "Finished epoch 3/10, batch 0. Loss: 1.706.\n",
      "Finished epoch 3/10, batch 200. Loss: 1.484.\n",
      "Finished epoch 3/10, batch 400. Loss: 1.394.\n",
      "Finished epoch 3/10, batch 600. Loss: 1.347.\n",
      "Finished epoch 3/10, batch 800. Loss: 1.094.\n",
      "Finished epoch 3/10, batch 1000. Loss: 1.357.\n",
      "Finished epoch 3/10, batch 1200. Loss: 1.483.\n",
      "Finished epoch 3/10, batch 1400. Loss: 1.029.\n",
      "Finished epoch 3. avg loss: 1.3683954923868331; median loss: 0.8242694735527039\n",
      "Finished epoch 4/10, batch 0. Loss: 1.327.\n",
      "Finished epoch 4/10, batch 200. Loss: 1.326.\n",
      "Finished epoch 4/10, batch 400. Loss: 1.516.\n",
      "Finished epoch 4/10, batch 600. Loss: 1.455.\n",
      "Finished epoch 4/10, batch 800. Loss: 1.455.\n",
      "Finished epoch 4/10, batch 1000. Loss: 1.264.\n",
      "Finished epoch 4/10, batch 1200. Loss: 1.183.\n",
      "Finished epoch 4/10, batch 1400. Loss: 1.403.\n",
      "Finished epoch 4. avg loss: 1.296982744338035; median loss: 0.715129554271698\n",
      "Finished epoch 5/10, batch 0. Loss: 1.513.\n",
      "Finished epoch 5/10, batch 200. Loss: 1.484.\n",
      "Finished epoch 5/10, batch 400. Loss: 0.869.\n",
      "Finished epoch 5/10, batch 600. Loss: 0.864.\n",
      "Finished epoch 5/10, batch 800. Loss: 1.392.\n",
      "Finished epoch 5/10, batch 1000. Loss: 1.699.\n",
      "Finished epoch 5/10, batch 1200. Loss: 1.527.\n",
      "Finished epoch 5/10, batch 1400. Loss: 1.036.\n",
      "Finished epoch 5. avg loss: 1.2470163554239182; median loss: 0.7198798060417175\n",
      "Finished epoch 6/10, batch 0. Loss: 1.391.\n",
      "Finished epoch 6/10, batch 200. Loss: 1.185.\n",
      "Finished epoch 6/10, batch 400. Loss: 1.183.\n",
      "Finished epoch 6/10, batch 600. Loss: 1.528.\n",
      "Finished epoch 6/10, batch 800. Loss: 1.402.\n",
      "Finished epoch 6/10, batch 1000. Loss: 1.349.\n",
      "Finished epoch 6/10, batch 1200. Loss: 1.476.\n",
      "Finished epoch 6/10, batch 1400. Loss: 1.640.\n",
      "Finished epoch 6. avg loss: 1.2092364381615046; median loss: 0.6886485815048218\n",
      "Finished epoch 7/10, batch 0. Loss: 1.063.\n",
      "Finished epoch 7/10, batch 200. Loss: 0.900.\n",
      "Finished epoch 7/10, batch 400. Loss: 1.152.\n",
      "Finished epoch 7/10, batch 600. Loss: 1.671.\n",
      "Finished epoch 7/10, batch 800. Loss: 1.224.\n",
      "Finished epoch 7/10, batch 1000. Loss: 1.109.\n",
      "Finished epoch 7/10, batch 1200. Loss: 1.293.\n",
      "Finished epoch 7/10, batch 1400. Loss: 1.259.\n",
      "Finished epoch 7. avg loss: 1.1742301879978607; median loss: 0.6198084950447083\n",
      "Finished epoch 8/10, batch 0. Loss: 1.118.\n",
      "Finished epoch 8/10, batch 200. Loss: 1.255.\n",
      "Finished epoch 8/10, batch 400. Loss: 1.238.\n",
      "Finished epoch 8/10, batch 600. Loss: 1.750.\n",
      "Finished epoch 8/10, batch 800. Loss: 1.138.\n",
      "Finished epoch 8/10, batch 1000. Loss: 1.527.\n",
      "Finished epoch 8/10, batch 1200. Loss: 1.341.\n",
      "Finished epoch 8/10, batch 1400. Loss: 0.875.\n",
      "Finished epoch 8. avg loss: 1.1514241900569113; median loss: 0.6431064605712891\n",
      "Finished epoch 9/10, batch 0. Loss: 0.719.\n",
      "Finished epoch 9/10, batch 200. Loss: 1.446.\n",
      "Finished epoch 9/10, batch 400. Loss: 0.914.\n",
      "Finished epoch 9/10, batch 600. Loss: 0.927.\n",
      "Finished epoch 9/10, batch 800. Loss: 1.012.\n",
      "Finished epoch 9/10, batch 1000. Loss: 1.123.\n",
      "Finished epoch 9/10, batch 1200. Loss: 1.261.\n",
      "Finished epoch 9/10, batch 1400. Loss: 1.051.\n",
      "Finished epoch 9. avg loss: 1.1225617870411961; median loss: 0.5962265729904175\n",
      "Finished epoch 10/10, batch 0. Loss: 0.938.\n",
      "Finished epoch 10/10, batch 200. Loss: 1.026.\n",
      "Finished epoch 10/10, batch 400. Loss: 0.892.\n",
      "Finished epoch 10/10, batch 600. Loss: 1.223.\n",
      "Finished epoch 10/10, batch 800. Loss: 1.055.\n",
      "Finished epoch 10/10, batch 1000. Loss: 0.908.\n",
      "Finished epoch 10/10, batch 1200. Loss: 1.044.\n",
      "Finished epoch 10/10, batch 1400. Loss: 0.669.\n",
      "Finished epoch 10. avg loss: 1.1084050065191298; median loss: 0.5273211598396301\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That completes our initial model definition. I added checkpointing and metrics tracking (via `send_metric`) to the following training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../models/train_basic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/train_basic.py\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from spell.metrics import send_metric\n",
    "\n",
    "import os\n",
    "CWD = os.environ[\"PWD\"]\n",
    "if not os.path.exists(f\"{CWD}/checkpoints/\"):\n",
    "    os.mkdir(f\"{CWD}/checkpoints/\")\n",
    "IS_GPU = torch.cuda.is_available()\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=True, transform=transform_train, download=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(*[\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25)\n",
    "        ])\n",
    "        self.cnn_block_2 = nn.Sequential(*[\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25)\n",
    "        ])\n",
    "        self.flatten = lambda inp: torch.flatten(inp, 1)\n",
    "        self.head = nn.Sequential(*[\n",
    "            nn.Linear(64 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        ])\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.cnn_block_1(X)\n",
    "        X = self.cnn_block_2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.head(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "clf = CIFAR10Model()\n",
    "if IS_GPU:\n",
    "    clf.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clf.parameters())\n",
    "\n",
    "\n",
    "def train():\n",
    "    NUM_EPOCHS = 10\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        losses = []\n",
    "\n",
    "        for i, (X_batch, y_cls) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if IS_GPU:\n",
    "                y = y_cls.cuda()\n",
    "                X_batch = X_batch.cuda()\n",
    "\n",
    "            y_pred = clf(X_batch)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_loss = loss.item()\n",
    "            if i % 200 == 0:\n",
    "                print(\n",
    "                    f'Finished epoch {epoch}/{NUM_EPOCHS}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "                )\n",
    "                send_metric(\"loss\", curr_loss)\n",
    "\n",
    "            losses.append(curr_loss)\n",
    "\n",
    "        print(\n",
    "            f'Finished epoch {epoch}. '\n",
    "            f'avg loss: {np.mean(losses)}; median loss: {np.median(losses)}'\n",
    "        )\n",
    "\n",
    "        torch.save(clf.state_dict(), f\"{CWD}/checkpoints/epoch_{epoch}.pth\")\n",
    "    torch.save(clf.state_dict(), f\"{CWD}/checkpoints/model_final.pth\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are on a dirty commit because we created this notebook file and this model training script in a Spell workspace, and it does not yet exist in the backing `git` repository (for more on how Spell runs and workspaces interact with git refer to [\"How runs interact with git\"](https://spell.ml/docs/run_overview#how-runs-interact-with-git) in our docs). The good news is that this is easy to do using our built-in JupyterLab git extension ([`jupyterlab/jupyterlab-git`](https://github.com/jupyterlab/jupyterlab-git)) on the sidebar:\n",
    "\n",
    "![](https://i.imgur.com/zRUN7vh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33mWARNING: \u001b[0mLog out failed for previous session: Unknown Server Error\n",
      "\u001b[0m\u001b[0mHello, Aleksey Bilogur!\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# This is temporarily necessary.\n",
    "# !spell login --identity aleksey@spell.ml --password jF4D@4#meRZF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m💫 Casting spell #90…\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[1m\u001b[36m⭐\u001b[0m Machine_Requested… Run created -- waiting for a t4 machine.\u001b[0mm^C\n",
      "\n",
      "\u001b[0m✨ Your run is still running remotely.\n",
      "\u001b[0m✨ Use 'spell kill 90' to terminate your run\n",
      "\u001b[0m✨ Use 'spell logs 90' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type t4 \\\n",
    "    --github-url https://github.com/spellml/cnn-cifar10.git \\\n",
    "    python models/train_basic.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improved model training script\n",
    "\n",
    "The following updated training script includes several additional bells and whistles typical of a Spell run model training script:\n",
    "\n",
    "* Model checkpointing has been added. If a checkpoint file is present, the training job will resume from the latest checkpoint automatically.\n",
    "* It uses the dataset on disk, if it already exists.\n",
    "* The number of epochs, convolutional block dropout, output head dropout, convolutional filter count, and dense layer filter count are all configurable using command line arguments.\n",
    "* Logs to Spell metrics.\n",
    "* Logs to Tensorboard.\n",
    "* Uses a validation set, and generates validation statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../models/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/train.py\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "from spell.metrics import send_metric\n",
    "\n",
    "import re\n",
    "import os\n",
    "CWD = os.environ[\"PWD\"]\n",
    "if not os.path.exists(f\"{CWD}/checkpoints/\"):\n",
    "    os.mkdir(f\"{CWD}/checkpoints/\")\n",
    "writer = SummaryWriter(f\"{CWD}/tensorboard/\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', type=int, dest='epochs', default=20)\n",
    "parser.add_argument('--batch_size', type=int, dest='batch_size', default=32)\n",
    "\n",
    "parser.add_argument('--conv1_filters', type=int, dest='conv1_filters', default=32)\n",
    "parser.add_argument('--conv2_filters', type=int, dest='conv2_filters', default=64)\n",
    "parser.add_argument('--dense_layer', type=int, dest='dense_layer', default=512)\n",
    "\n",
    "parser.add_argument('--conv1_dropout', type=float, dest='conv1_dropout', default=0.25)\n",
    "parser.add_argument('--conv2_dropout', type=float, dest='conv2_dropout', default=0.25)\n",
    "parser.add_argument('--dense_dropout', type=float, dest='dense_dropout', default=0.5)\n",
    "\n",
    "parser.add_argument('--from_checkpoint', type=str, dest='from_checkpoint', default=\"\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Used for testing purposes.\n",
    "# class Args:\n",
    "#     def __init__(self):\n",
    "#         self.epochs = 50\n",
    "#         self.batch_size = 32\n",
    "#         self.conv1_filters = 32\n",
    "#         self.conv2_filters = 64\n",
    "#         self.dense_layer = 512\n",
    "#         self.conv1_dropout = 0.25\n",
    "#         self.conv2_dropout = 0.25\n",
    "#         self.dense_dropout = 0.5\n",
    "#         self.from_checkpoint = False\n",
    "# args = Args()\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "download = not os.path.exists(\"/mnt/cifar10/\")\n",
    "if download:\n",
    "    print(\"CIFAR10 dataset not on disk, downloading...\")\n",
    "else:\n",
    "    print(\"CIFAR10 dataset is already on disk! Skipping download.\")\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=True, transform=transform_train, download=download)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=False, transform=transform_test, download=download)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(*[\n",
    "            nn.Conv2d(3, args.conv1_filters, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(args.conv1_filters, args.conv2_filters, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(args.conv1_dropout)\n",
    "        ])\n",
    "        self.cnn_block_2 = nn.Sequential(*[\n",
    "            nn.Conv2d(args.conv2_filters, args.conv2_filters, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(args.conv2_filters, args.conv2_filters, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(args.conv2_dropout)\n",
    "        ])\n",
    "        self.flatten = lambda inp: torch.flatten(inp, 1)\n",
    "        self.head = nn.Sequential(*[\n",
    "            nn.Linear(args.conv2_filters * 8 * 8, args.dense_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(args.dense_dropout),\n",
    "            nn.Linear(args.dense_layer, 10)\n",
    "        ])\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.cnn_block_1(X)\n",
    "        X = self.cnn_block_2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.head(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "clf = CIFAR10Model()\n",
    "\n",
    "if args.from_checkpoint:\n",
    "    if args.from_checkpoint == \"latest\":\n",
    "        start_epoch = max([int(re.findall(\"[0-9]{1,2}\", fp)[0]) for fp in os.listdir(\"/mnt/checkpoints/\")])\n",
    "    else:\n",
    "        start_epoch = args.from_checkpoint\n",
    "    clf.load_state_dict(torch.load(f\"/mnt/checkpoints/epoch_{start_epoch}.pth\"))\n",
    "    print(f\"Resuming training from epoch {start_epoch}...\")\n",
    "else:\n",
    "    start_epoch = 1\n",
    "\n",
    "clf.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(clf.parameters(), lr=0.0001, weight_decay=1e-6)\n",
    "\n",
    "\n",
    "def test(epoch, num_epochs):\n",
    "    losses = []\n",
    "    n_right, n_total = 0, 0\n",
    "    clf.eval()\n",
    "\n",
    "    for i, (X_batch, y_cls) in enumerate(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            y = y_cls.cuda()\n",
    "            X_batch = X_batch.cuda()\n",
    "\n",
    "            y_pred = clf(X_batch)\n",
    "            loss = criterion(y_pred, y)\n",
    "            losses.append(loss.item())\n",
    "            _, y_pred_cls = y_pred.max(1)\n",
    "            n_right, n_total = n_right + (y_pred_cls == y_cls.cuda()).sum().item(), n_total + len(X_batch)\n",
    "\n",
    "    val_acc = n_right / n_total\n",
    "    val_loss = np.mean(losses)\n",
    "    send_metric(\"val_loss\", val_loss)\n",
    "    send_metric(\"val_acc\", val_acc)\n",
    "    writer.add_scalar(\"val_loss\", val_loss, (len(train_dataloader) // 200 + 1) * epoch + (i // 200))\n",
    "    writer.add_scalar(\"val_acc\", val_acc, (len(train_dataloader) // 200 + 1) * epoch + (i // 200))\n",
    "    print(\n",
    "        f'Finished epoch {epoch}/{num_epochs} avg val loss: {val_loss:.3f}; median val loss: {np.median(losses):.3f}; '\n",
    "        f'val acc: {val_acc:.3f}.'\n",
    "    )\n",
    "\n",
    "\n",
    "def train():\n",
    "    clf.train()\n",
    "    NUM_EPOCHS = args.epochs\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS + 1):\n",
    "        losses = []\n",
    "\n",
    "        for i, (X_batch, y_cls) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y = y_cls.cuda()\n",
    "            X_batch = X_batch.cuda()\n",
    "\n",
    "            y_pred = clf(X_batch)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss = loss.item()\n",
    "            if i % 200 == 0:\n",
    "                print(\n",
    "                    f'Finished epoch {epoch}/{NUM_EPOCHS}, batch {i}. loss: {train_loss:.3f}.'\n",
    "                )\n",
    "                send_metric(\"train_loss\", train_loss)\n",
    "                writer.add_scalar(\"train_loss\", train_loss, (len(train_dataloader) // 200 + 1) * epoch + (i // 200))\n",
    "            losses.append(train_loss)\n",
    "\n",
    "        print(\n",
    "            f'Finished epoch {epoch}. '\n",
    "            f'avg loss: {np.mean(losses)}; median loss: {np.median(losses)}'\n",
    "        )\n",
    "        test(epoch, NUM_EPOCHS)\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(clf.state_dict(), f\"{CWD}/checkpoints/epoch_{epoch}.pth\")\n",
    "\n",
    "    torch.save(clf.state_dict(), f\"{CWD}/checkpoints/model_final.pth\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some test runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m💫 Casting spell #94…\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[0m^C\n",
      "\n",
      "\u001b[0m✨ Your run is still running remotely.\n",
      "\u001b[0m✨ Use 'spell kill 94' to terminate your run\n",
      "\u001b[0m✨ Use 'spell logs 94' to view logs again\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type t4 \\\n",
    "    --github-url https://github.com/spellml/cnn-cifar10.git \\\n",
    "    --tensorboard-dir /spell/tensorboard/ -- \\\n",
    "    python models/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m💫 Casting spell #93…\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Machine_Requested… done\n",
      "\u001b[1m\u001b[36m⭐\u001b[0m Building… Machine acquired -- commencing run\u001b[0mm^C\n",
      "\n",
      "\u001b[0m✨ Your run is still running remotely.\n",
      "\u001b[0m✨ Use 'spell kill 93' to terminate your run\n",
      "\u001b[0m✨ Use 'spell logs 93' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type t4 \\\n",
    "    --github-url https://github.com/spellml/cnn-cifar10.git \\\n",
    "    --tensorboard-dir /spell/tensorboard/ -- \\\n",
    "    python models/train.py --batch_size 64 --dense_dropout 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m💫 Casting spell #100…\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Building… doneuired -- commencing run\u001b[0m\n",
      "\u001b[1m\u001b[36m🌟\u001b[0m Machine_Requested… Run created -- waiting for a t4 machine.\u001b[0m^C\n",
      "\n",
      "\u001b[0m✨ Your run is still running remotely.\n",
      "\u001b[0m✨ Use 'spell kill 100' to terminate your run\n",
      "\u001b[0m✨ Use 'spell logs 100' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type t4 \\\n",
    "    --github-url https://github.com/spellml/cnn-cifar10.git \\\n",
    "    --tensorboard-dir /spell/tensorboard/ \\\n",
    "    --mount runs/94/checkpoints/:/mnt/checkpoints/ \\\n",
    "    --mount uploads/cifar10/:/mnt/cifar10/ -- \\\n",
    "    python models/train.py --from_checkpoint latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spell hyper grid \\\n",
    "    --machine-type t4 \\\n",
    "    --param batch_size=16,32,64 \\\n",
    "    --param conv2_filters=32,64 \\\n",
    "    --github-url https://github.com/spellml/cnn-cifar10.git \\\n",
    "    --tensorboard-dir /spell/tensorboard/ \\\n",
    "    --mount uploads/cifar10/:/mnt/cifar10/ -- \\\n",
    "    python models/train.py \\\n",
    "        --epochs 20 \\\n",
    "        --batch_size :batch_size: \\\n",
    "        --conv2_filters :conv2_filters:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}